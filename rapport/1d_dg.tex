\documentclass[a4paper,10pt,draft]{article}

\usepackage{ucs}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{caption}
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage[pdftex]{graphicx}
\usepackage{ stmaryrd }
\usepackage{fullpage}

\usepackage{hyperref}

\title{1D DG method}
\author{Etienne PEILLON}
\date{15/05/2019}

\begin{document}
 \maketitle
 
 \section{Problem}
 
 We consider the following problem:
 
 \begin{equation} \label{eq:initial}
  \alpha u - \mu \Delta u = f
 \end{equation}

 on the interval $\Omega = ]a,b[$ with one of the three following boundary conditions:
 \begin{itemize}
  \item Dirichlet conditions: $u(a) = u_a^D$ and $u(b) = u_b^D$;
  \item Neumann conditions: $u'(a) = u_a^N$ and $u'(b) = u_b^N$;
  \item Mixed conditions: $u(a) + \gamma_a u'(a) = u_a^M$ and $u(b) + \gamma_b u'(b) = u_b^M$.
 \end{itemize}

 \section{Discontinuous discretization}
 
 To discretize the problem we will follow some step:
 \begin{enumerate}
  \item weak formulation of the problem compatible with the method
  \item writing of the basic matrix
  \item implementation
 \end{enumerate}
 
 The goal of this report is simple: give a little overview of the DG method with understandable but 
extendable notations.

 \subsection{Weak formulation}
 
 Let be a subdivision $a = x_0 < x_1 < \dots < x_{K-1} < x_K = b$ of I. We write $C_n = 
]x_{n-1},x_n[$, so that we have $K$ cells, and $\mathcal{E}_h = \{ C_n \}$ where $h = \max 
\limits_{n} |C_n|$. We also note $h_n = |C_n| = x_n - x_{n-1}$.
 
 We consider the broken Sobolev space, highly depending on the subdivision of the domain (see 
Riviere):
 \begin{equation}
  H^1(\mathcal{E}_h) := \{ v \in L^2(\Omega) \quad that \quad \forall E \in \mathcal{E}_h, v|_E \in 
H^1(E) \}
 \end{equation}

 Denote that $H^1(\Omega) \subset H^1(\mathcal{E}_h)$.
 
 \paragraph{}
 The strong idea of discontinuous Galerkin method is to approximate the problem, not with an 
approximation of $H^1(\Omega)$ as for continuous Galerkin method, but with an approximation of 
$H^1(\mathcal{E}_h)$.


\paragraph{}
Let be $v \in H^1(\mathcal{E}_h)$, and multiply \ref{eq:initial} by it and then use Green formula 
(also known as integration by parts in 1D). We take care that Green formula works only on each cell:

\begin{equation}\label{eq:weak}
 \sum \limits_{n=1}^K \int_{C_n} (\mu \nabla u \nabla v + \alpha uv) d\omega - \int_{\partial C_n} 
\mu \nabla u \cdot \mathbf{n}\ v\ d\gamma = 
\sum \limits_{n=1}^K \int_{C_n}  f\ v\ d\omega
\end{equation}

Here exists different methods in the literature. In Riviere, terms are added to create a bi-linear 
symmetric coercive and continuous form on left side and a linear conituous form on the right side, 
so that you can prove existence and uniqueness with functional analysis theorems. The approach is 
very interesting in the theorical way, but complicated for just a simple implementation.

On the other hand, you can use the following approach, which is less general, but more 
understandable as first view of the subject:

\paragraph{}
Because $v \in H^1(\mathcal{E}_h)$, we assume $u \in H^1(\mathcal{E}_h)$ for the resolution of the 
problem, but we want equality of the solution on the common edges of each cell, wich means we have 
a bad-defined value at $u'(x_n)$ in our case, wich is the \emph{numerical flux}.

A solution consists on assuming numerical flux equals one unique value on cell frontiers:

$$
\widehat{\nabla u(x)} = \frac{\beta}{2} \llbracket u \rrbracket\mathbf{n} + \overline{\nabla u(x)} 
= \frac{\beta}{2} (u^+(x) - u^-(x)) \mathbf{n} + \frac{\nabla u^+(x) + \nabla u^-(x)}{2}
$$

where the definition of the different term are given in Armand's paper p.15.


\paragraph{TRUE section}
\begin{itshape}
 Finally, because $v \in H^1(\mathcal{E}_h)$, we have this equality for each elements:

$$
\int_{C_n} (\mu \nabla u \nabla v + \alpha uv) d\omega - \int_{\partial C_n} \mu \nabla u \cdot 
\mathbf{n}\ v\ d\gamma = \int_{C_n}  f\ v\ d\omega
$$
\end{itshape}


\subsection{$H^1(\mathcal{E}_h)$ discretization}

 $H^1(\mathcal{E}_h)$ discretization is quite similar with the discretization of $H^1(\Omega)$. Let 
be a cell $C_k \in \mathcal{E}_h$, then consider $(\phi_n^k)_{n=0,\dots,N}$ a basis of 
polynomials of degree $N$ on $C_k$. We assume $\phi_n^k|_{C_k^c}=0$.

\paragraph{}
We call $\mathcal{D}_N(\mathcal{E}_h) = \mathrm{span}\{ \phi_n^k ,\ 0\leq n \leq N,\ 1\leq k 
\leq K \}$ the approximation of $H^1(\mathcal{E}_h)$. Then we have to choose the type of basis 
function. Here is some possibilities:
\begin{itemize}
 \item monomial functions,
 \item lagrangian functions,
 \item legendrian functions.
\end{itemize}

Obviously, each basis function is the image of a basis function on a reference element composed 
with an affine map. We call $E$ the physical element and $\hat E$ the reference element, and
\begin{equation*}
 F_E : E \longrightarrow \hat E \qquad \text{and} \qquad  F_E^{-1} : \hat E \longrightarrow  E
\end{equation*}
the affine maps between $E$ and $\hat E$.

Since those maps are affine, we have $|\mathrm{det}(\mathrm{D}F_E^{-1})| = 
|\mathrm{det}(\mathrm{D}F_E)|^{-1} = \dfrac{|E|}{|\hat E|}$.

We also express physical basis functions with reference basis functions with the formula 
\begin{equation*}
 \phi_i^E = \sqrt{\dfrac{|\hat E|}{|E|}}\ \hat \phi_i \circ F_E
\end{equation*}
so that $\|\phi_i^E\|_{L^2(E)}=1$ and $\|\hat \phi_i^E\|_{L^2(E)}=1$.

For 1D case, the reference element will be the segment $\hat E = [-1,1]$. Then 
the affine map will be:

\begin{equation*}
\begin{array}{cccc}
 F_k^{-1} : & [-1,1] & \longrightarrow & [x_{k-1},x_k] \\
            & x & \longmapsto & \dfrac{h_k}{2} x + \dfrac{x_{k-1}+x_k}{2}
\end{array}
\text{ and }
\begin{array}{cccc}
 F_k : & [a,b] & \longrightarrow & [-1,1] \\
            & y & \longmapsto & \dfrac{2}{h_k} \left(y - \dfrac{x_{k-1}+x_k}{2}\right)
\end{array}
\end{equation*}

 With this map, we now just have to describe the basis functions on the reference element to have 
every basis functions we need. So we define the basis functions on the reference element by $\hat 
\phi_n$ for $n= 0, \dots , N$ and then we can write $\phi_n^k = \sqrt{\frac{2}{h_k}} \hat 
\phi_n \circ F_k$

\subsection{discretization on each cell}

In this part, we assume $u \in \mathcal{D}_N(\mathcal{E}_h)$ and it can be decomposed as:

$$
u = \sum_{k=1}^K u^k = \sum_{k=1}^K \sum_{n=0}^N u_n^k \phi_n^k
$$

where $\forall n,k,\ u_n^k \in \mathbb{R}$.


Then we can inject $u$ in the equation \ref{eq:weak}. Then we define $U^k = 
(u_0^k, \dots , u_N^k)^\top$ and $U = [U^1, \dots , U^K]^\top$. The next idea is to project the 
equation \ref{eq:weak} on $\mathcal{D}_N(\mathcal{E}_h)$.

\subsubsection{right term}

The right term of the equation is the easiest part of the discretization: we define $F = [F^1, 
\dots , F^K]^\top$ and $F^k = 
(f_0^k, \dots , f_N^k)^\top$ where $f_i^k = \int_{C_k} f \phi_i^k d\omega$.



\subsubsection{discretization of the mass and stiffness term}

Consider $\int_{C_E} (\mu \nabla u  \cdot \nabla v + \alpha uv) d\omega$, and take $v = \phi_n^E$. 
Then 
we can discretize this integral by

\begin{equation}
 \left( \alpha \mathbb{M}^E + \mu \mathbb{S}^E  \right) U^E
\end{equation}

where $\mathbb{M}^E_{i,j} = \int_{C_E} \phi_i^E \phi_j^E d\omega$ and $\mathbb{S}_{i,j}^E =
\int_{C_E} \nabla \phi_i^E \nabla \phi_j^E d\omega$

Because $\phi_n^E = \sqrt{\frac{|\hat E|}{|E|}} \hat \phi_n \circ F_E$, we have 
$\mathrm{D}\phi_n^E = \sqrt{\frac{|\hat E|}{|E|}} \mathrm{D}\hat \phi_n(F_E) \circ \mathrm{D} F_E$ 
and, confusing matrices and differential, $\nabla \phi_n^E = \sqrt{\frac{|\hat E|}{|E|}} 
{\mathrm{D} F_E}^\top \nabla \hat \phi_n(F_E) $:

\begin{equation*}
 \mathbb{M}^E_{i,j} = \int_{C_E} \phi_i^E \phi_j^E d\omega = 
 \frac{|\hat E|}{|E|} \int_{\hat E} \hat \phi_i \hat \phi_j d\hat \omega \cdot 
|\mathrm{det}(\mathrm{D} F_E^{-1})| = 
\int_{\hat E} \hat \phi_i \hat \phi_j d\hat \omega =\widehat{\mathbb{M}}_{i,j}
\end{equation*}
and
\begin{align*}
 \mathbb{S}_{i,j}^E &= \int_{C_E} \nabla \phi_i^E \cdot \nabla \phi_j^E d\omega = 
\int_{\hat E} \nabla \hat \phi_i \cdot ( \mathrm{D} F_E{\mathrm{D} F_E}^\top \nabla \hat 
\phi_j) d\hat \omega \\
&= \left( {\mathrm{D} F_E}^\top \nabla \hat \phi_i , {\mathrm{D} F_E}^\top \nabla \hat \phi_i  
\right)_{L^2(\hat E)}
\end{align*}

Of course, those formulae simplify a lot in 1D, but those are general and will be reused. But the 
one dimension gives:
\begin{equation*}
 \mathbb{M}^k_{i,j} =  {\widehat{\mathbb{M}}}_{i,j} \qquad \text{and} \qquad
 \mathbb{S}_{i,j}^k =  \frac{4}{h_k^2} \left( \hat \phi_i' , \hat \phi_j ' 
\right)_{L^2(]-1,1[)} = \frac{4}{h_k^2} \widehat{\mathbb{S}}_{i,j}
\end{equation*}

Finally, we obtain $(\alpha \mathbb{M} + \mu \mathbb{S})U$ where $\mathbb{M} = \mathrm{diag} ( 
\mathbb{M}^1, \dots, \mathbb{M}^K)$ and  $\mathbb{S} = \mathrm{diag} 
(\mathbb{S}^1,\dots,\mathbb{S}^K)$.

\subsubsection{Flux discretization}

In the same way than Armand's report, we define $\mathbb{F}$ as the matrix describing the flux 
part. This the most complicated term, and the one wich will be treated here with less generality.

\paragraph{flux between interior elements}

Let be an interior element, without common component with the boundary. Assuming that the normal 
vector is constant by part, we can cut the integral on each part in $D$ integrals:

\begin{multline*}
 \int_{\partial E} \widehat{\nabla u}_E \cdot \mathbf{n}_E\ v\ d\gamma 
 = \int_{\partial E} \widehat{\nabla u}_E \cdot \mathbf{n}_E\ v\ d\gamma
 = \int_{\partial E} \left( \frac{\beta}{2} {u^+}_E + \frac{1}{2} \nabla {u^+}_E \cdot \mathbf{n}_E 
\right) \ v\ d\gamma \\
+ \int_{\partial E} \left( -\frac{\beta}{2} {u^-}_E + \frac{1}{2} \nabla {u^-}_E \cdot \mathbf{n}_E 
\right) \ v\ d\gamma
\end{multline*}
 We call the first integral the self interaction flux and the second integral the neighbor 
interaction flux.

\subparagraph{self interaction flux} 
Since we have
\begin{equation*}
 \frac{\beta}{2} {u^+}_E + \frac{1}{2} \nabla {u^+}_E \cdot \mathbf{n}_E = \sum_{j=0}^N u_j^E 
\left( \frac{\beta}{2} \phi_j^E + \frac{1}{2} \nabla \phi_j^E \cdot \mathbf{n}_E \right)
\end{equation*}
the self interaction flux matrix can be written as
\begin{equation*}
 \mathbb{F}_{i,j}^{E,s} = \int_{\partial E} \left( \frac{\beta}{2} \phi_j^E + \frac{1}{2} \nabla 
\phi_j^E \cdot \mathbf{n}_E \right) \phi_i^E \ d \gamma
\end{equation*}

Then we can assemble the self interaction flux matrices: $\mathbb{F}^s = {\mathrm{diag}}_{E 
\in \mathcal{E}_h} (\mathbb{F}_{i,j}^{E,s})$.

\subparagraph{neighbor interaction flux}
Firstly, we cut the integral by faces and we call $E^d$ the neighbor of $E$ by the common face 
$\partial E^d$:
\begin{equation*}
 \int_{\partial E} \left( -\frac{\beta}{2} {u^-}_E + \frac{1}{2} \nabla {u^-}_E \cdot \mathbf{n}_E 
\right) \ v\ d\gamma = \sum_{d=1}^D \int_{\partial E^d} \left( -\frac{\beta}{2} {u^-}_E^d + 
\frac{1}{2} \nabla {u^-}_E^d \cdot \mathbf{n}_E^d \right) \ \phi_i^E\ d\gamma
\end{equation*}

In exactly the same way than the self interaction flux, the interaction flux matrice between $E$ 
and $E^d$ is:
\begin{equation*}
 \mathbb{F}_{i,j}^{E,E^d} = \int_{\partial E^d} \left( -\frac{\beta}{2} \phi_j^{E^d} + \frac{1}{2} 
\nabla \phi_j^{E^d} \cdot \mathbf{n}_E^d \right) \phi_i^E \ d \gamma
\end{equation*}

Then we can assemble those matrices as $\mathbb{F}^E = \mathrm{row}_{E^d \in \mathcal{E}_h} 
(\mathbb{F}^{E,E^d})$, where $\mathbb{F}^{E,E^d} = 0$ if $E$ and $E^d$ are not neighbor and 
$\mathbb{F}^I = \mathrm{col}_{E \in \mathcal{E}_h} 
(\mathbb{F}^E)$.
\iffalse
{\itshape
\begin{align*}
  \int_{\partial E} \widehat{\nabla u}_E \cdot \mathbf{n}_E\ v\ d\gamma &=
  \sum_{d=1}^D \int_{\partial E^d} \widehat{\nabla u}_E \cdot \mathbf{n}_E^d\ v\ d\gamma \\
  &= \sum_{d=1}^D \int_{\partial E^d} \left(\frac{\beta}{2} ({u^+}_E^d - {u^-}_E^d) + \frac{1}{2} 
(\nabla {u^+}_E^d + \nabla {u^-}_E^d) \cdot \mathbf{n}_E^d \right)\ v\ d\gamma
\end{align*}

The goal is to write $\int_{\partial E^d} \widehat{\nabla u}_E \cdot \mathbf{n}_E^d\ \phi_i^E \ 
d\gamma$ as a matrices product $\mathbb{F}_i U$. We can make a separation between the terms of the 
last integral:
\begin{multline*}
 \int_{\partial E^d} \widehat{\nabla u}_E \cdot \mathbf{n}_E^d\ \phi_i^E \ d\gamma
= \int_{\partial E^d} \left( \frac{\beta}{2} {u^+}_E^d + \frac{1}{2} \nabla {u^+}_E^d \cdot 
\mathbf{n}_E^d \right) \ \phi_i^E\ d\gamma \\
+ \int_{\partial E^d} \left( -\frac{\beta}{2} {u^-}_E^d + \frac{1}{2} \nabla {u^-}_E^d \cdot 
\mathbf{n}_E^d \right) \ \phi_i^E\ d\gamma
 \end{multline*}





Let be an interior element. In our case, that means we consider $C_k = [x_{k-1},x_k]$ with $1<k<K$. 
Then we have
\begin{align*}
 \int_{\partial C_n} \widehat{\nabla u}_k \cdot \mathbf{n}_k\ v\ d\gamma &= \int_{\partial C_n} 
\left(\frac{\beta}{2} \llbracket u \rrbracket_k + \overline{\nabla u(x)} \cdot \mathbf{n}_k 
\right)\ v\ d\gamma \\
&= \int_{\partial C_n} \left(\frac{\beta}{2} (u^+_k + u^-_k) + \frac{1}{2} (\nabla u^+_k + \nabla 
u^-_k) \cdot \mathbf{n}_k \right)\ v\ d\gamma \\
\end{align*}

This last equality can be rewritten in 1D as
\begin{align*}
 \int_{\partial C_n} \widehat{\nabla u}_k \cdot \mathbf{n}_k\ v\ d\gamma &= \widehat{\nabla 
u}_k(x_k) \cdot \mathbf{n}_k(x_k)\ v(x_k) + \widehat{\nabla u}_k(x_k) \cdot \mathbf{n}_k(x_k)\ 
v(x_k)\\
 &=\left(\frac{\beta}{2} (u^+_k(x_k) - u^-_k(x_k)) + \frac{1}{2} \left(\frac{d}{dx} u^+_k(x_k) + 
\frac{d}{dx} u^-_k(x_k)\right) \mathbf{n}_k(x_k) \right)\ v(x_k) \ + \\
& \left(\frac{\beta}{2} (u^+_k(x_{k-1}) - u^-_k(x_{k-1})) + \frac{1}{2} \left(\frac{d}{dx} 
u^+_k(x_{k-1}) + \frac{d}{dx} u^-_k(x_{k-1})\right)\mathbf{n}_k(x_{k-1}) \right)\ v(x_{k-1})
\end{align*}

The differences between the two parts are the point of application and sign in front of the the 
average derivative, due to the normal direction.

Then we have to estimate a lot of values: $u^\pm_k$, $\nabla u^\pm_k$ and $\mathbf{n}_k$.

\subparagraph{$u^\pm_k$:}
We have
\begin{align*}
 u^+_k(x_k) = \sum_{n=0}^N u_n^k \phi_n^k(x_k) &= \sum_{n=0}^N u_n^k \hat \phi_n(1) \\
 u^-_k(x_k) = \sum_{n=0}^N u_n^{k+1} \phi_n^{k+1}(x_k) &= \sum_{n=0}^N u_n^{k+1} \hat 
\phi_n(-1)
\end{align*}
and
\begin{align*}
 u^+_k(x_{k-1}) = \sum_{n=0}^N u_n^k \phi_n^k(x_{k-1}) &= \sum_{n=0}^N u_n^k \hat \phi_n(-1) 
\\
 u^-_k(x_{k-1}) = \sum_{n=0}^N u_n^{k-1} \phi_n^{k-1}(x_{k-1}) &= \sum_{n=0}^N u_n^{k-1} \hat 
\phi_n(1)
\end{align*}

\subparagraph{$\nabla u^\pm_k$:} We have
\begin{align*}
 \nabla u^+_k(x_k) = \sum_{n=0}^N u_n^k \nabla \phi_n^k(x_k) &= \nabla F_k \sum_{n=0}^N 
u_n^k \nabla \hat \phi_n(1) \\
\nabla u^+_k(x_k) = \sum_{n=0}^N u_n^{k+1} \nabla \phi_n^{k+1}(x_k) &= \nabla F_{k+1} 
\sum_{n=0}^N u_n^{k+1} \nabla \hat \phi_n(-1)
\end{align*}
and
\begin{align*}
 \nabla u^+_k(x_{k-1}) = \sum_{n=0}^N u_n^k \nabla \phi_n^k(x_{k-1}) &= \nabla F_k \sum_{n=0}^N 
u_n^k \nabla \hat \phi_n(-1) \\
\nabla u^+_k(x_{k-1}) = \sum_{n=0}^N u_n^{k-1} \nabla \phi_n^{k-1}(x_{k-1}) &= \nabla F_{k-1} 
\sum_{n=0}^N 
u_n^{k-1} \nabla \hat \phi_n(1)
\end{align*}

\subparagraph{$\mathbf{n}_k$:} We simply have $\mathbf{n}_k(x_k) = 1$ and $\mathbf{n}_k(x_{k-1}) = 
-1$.

\paragraph{}

Then, for $j=0,\dots,N$,
\begin{multline*}
 \widehat{\nabla u}_k(x_k) \cdot \mathbf{n}_k(x_k)\ \phi_j^k(x_k) 
 = \Bigg[ \frac{\beta}{2} \left( \sum_{n=0}^N u_n^k \hat \phi_n(1) - \sum_{n=0}^N u_n^{k+1} 
\hat 
\phi_n(-1) \right) 
\\+ \frac{1}{2} \left(\nabla F_k \sum_{n=0}^N u_n^k \nabla \hat \phi_n(1) + \nabla F_{k+1} 
\sum_{n=0}^N u_n^{k+1} \nabla \hat \phi_n(-1) \right) \cdot \mathbf{n}_k(x_k) \Bigg] 
\hat \phi_j(1)
\end{multline*}
wich can be easily translated as vector product between a row matrix and $U$.

\paragraph{flux at the bound}
The flux at the bound is not complicated at all if we consider there is a virtual cell where the 
solution has the good properties. For example, with Dirichlet conditions, we consider that:
\begin{itemize}
 \item the virtual solution equals zero on the bound, →which means $\llbracket u \rrbracket = u^+ $,
 \item the virtual solution has the same derivative on the bound than the real solution, wich means 
$\overline{\nabla u} = \nabla u^+$.
\end{itemize}
}
\fi
\paragraph{}
At the end wa assembly all the flux matrix $\mathbb{F} = \mathbb{F}^s +\mathbb{F}^I $ and we obtain 
a system of this shape:
\begin{equation}
\left(\alpha \mathbb{M} + \mu (\mathbb{S}-\mathbb{F})\right) U = F
\end{equation}
Then, to obtain $U$, we just have to invert the matrix $\alpha \mathbb{M} + \mu 
(\mathbb{S}-\mathbb{F})$ wich is not easy with high dimension, even with iterative algorithm. An 
idea of efficient iterative algorithm could be biconjugate gradient algorithm.

\subsection{The Legendre polynomials}

The purpose of this part is to exploit Armand's results on the legendre polynomials for the 
construction of the differents matrices. So we define $\hat \phi_i = \sqrt{\dfrac{2i+1}{2}} P_i$ 
where $P_i$ is the i-th Legendre's polynomial.

\subsubsection{Mass matrix}
By their definition, the legendre polynomials are orthogonals for the scalar product 
$\int_{-1}^1 uv dx$. So, the reference mass matrix is just identity matrix.

\subsubsection{Stiffness matrix}
The stiffness matrix computation is more complicated because of the derivative. With the 
definition of basis function, we can already write:

\begin{equation*}
 \widehat{\mathbb{S}}_{i,j} = \frac{\sqrt{(2i+1)(2j+1)}}{2} \left( P_i' , P_j' \right)_{L^2(]-1,1[)}
\end{equation*}

But due to Armand, the majority part of the computation is already done: $\forall i\leq j \in 
\mathbb{N}$
\begin{itemize}
 \item $\left(P_{2i}',P_{2j+1}'\right)_{L^2(]-1,1[)} = 0$
 \item $\left(P_{2i}',P_{2j}'\right)_{L^2(]-1,1[)} = 2i(2i+1)$
 \item $\left(P_{2i+1}',P_{2j+1}'\right)_{L^2(]-1,1[)} = 2i(2i+3)+2$
\end{itemize}

As final result, we have $\mathbb{S}_{i,j}^k = \dfrac{2}{{h_k}^2} \sqrt{(2i+1)(2j+1)} \left( P_i' , 
P_j' \right)_{L^2(]-1,1[)} = \dfrac{2}{{h_k}^2} \mathbb{P}_{i,j}$. Note that result is consistent 
with Armand's result (pay attention that $\|P_0\| = 2$).

\subsubsection{Flux matrix}

The flux matrix is not as simple as the others. But with the one dimension, we can express it 
easily with this remark: $P_n(1) = (-1)^n P_n(-1) = 1$. This results:
\begin{align*}
 u^+_k(x_k) &= \frac{1}{\sqrt{h_k}} \sum_{n=0}^N \sqrt{2n+1} u_n^k\\
 u^-_k(x_k) &= \frac{1}{\sqrt{h_{k+1}}} \sum_{n=0}^N (-1)^n \sqrt{2n+1}\ u_n^{k+1}\\
 \nabla u_k^+ (x_k) &= \frac{2}{{h_k}^{3/2}} \sum_{n=0}^N \sqrt{2n+1} u_n^k P_n'(1) \\
 \nabla u_k^- (x_k) &= \frac{2}{{h_k}^{3/2}} \sum_{n=0}^N \sqrt{2n+1} u_n^{k+1} P_n'(-1)
\end{align*}
We need to process the values $P_n'(1)$ and $P_n'(-1)$. This is easy with Armand's work because
\begin{align*}
 P_{2n}' &= \sum_{i=0}^{n-1} (4i+3) P_{2i+1} \\
 P_{2n+1}' &= 1 + \sum_{i=1}^{n} (4i+1) P_{2i}
\end{align*}
Then we have $P_{2n}'(1) = -P_{2n}'(-1) = n(2n+1)$ and $P_{2n+1}'(1) = P_{2n+1}'(-1) = 1 + n(2n+3)$.


\end{document}
